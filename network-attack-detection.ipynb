{
 "cells": [
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Network Attack Detection using Machine Learning\n",
    "\n",
    "## Dataset description\n",
    "\n",
    "In the NetFlow V9 format by Cisco\n",
    "\n",
    "* **train_set**: ~2 million flows, used for training the model\n",
    "* **test_set**: ~4 million flows, used for testing the model\n",
    "\n",
    "### Columns\n",
    "* **FLOW_ID**: A unique identifier for the flow\n",
    "* **PROTOCOL_MAP**: A string representing the protocol used in the flow, possible values include \"ICMP\", \"TCP\", \"UDP\", \"IGMP\", \"GRE\", \"ESP\", \"AH\", \"EIGRP\", \"OSPF\", \"PIM\", \"IPV6-ICMP\", \"IPV6-IP\", \"IPV6-ROUTE\", \"IPV6-FRAG\", \"IPV6-NONXT\", \"IPV6-OPTS\", and others.\n",
    "* **L4_SRC_PORT**: The source port number in the flow, possible values range from 0 to 65535.\n",
    "* **IPV4_SRC_ADDR**: The source IPv4 address in the flow, represented as a string in dotted decimal notation (e.g., \"192.168.0.1\").\n",
    "* **L4_DST_PORT**: The destination port number in the flow, possible values range from 0 to 65535.\n",
    "* **IPV4_DST_ADDR**: The destination IPv4 address in the flow, represented as a string in dotted decimal notation (e.g., \"192.168.0.2\").\n",
    "* **FIRST_SWITCHED**: The time at which the flow started, measured in seconds since the epoch (January 1, 1970).\n",
    "* **FLOW_DURATION_MILLISECONDS**: The duration of the flow in milliseconds.\n",
    "* **LAST_SWITCHED**: The time at which the flow ended, measured in seconds since the epoch (January 1, 1970).\n",
    "* **PROTOCOL**: The protocol used in the flow, possible values include 1 (ICMP), 6 (TCP), 17 (UDP), and others.\n",
    "* **TCP_FLAGS**: The TCP flags set in the flow, represented as a binary string (e.g., \"100101\").\n",
    "* **TCP_WIN_MAX_IN**: The maximum advertised window size (in bytes) for incoming traffic.\n",
    "* **TCP_WIN_MAX_OUT**: The maximum advertised window size (in bytes) for outgoing traffic.\n",
    "* **TCP_WIN_MIN_IN**: The minimum advertised window size (in bytes) for incoming traffic.\n",
    "* **TCP_WIN_MIN_OUT**: The minimum advertised window size (in bytes) for outgoing traffic.\n",
    "* **TCP_WIN_MSS_IN**: The maximum segment size (in bytes) for incoming traffic.\n",
    "* **TCP_WIN_SCALE_IN**: The window scale factor for incoming traffic.\n",
    "* **TCP_WIN_SCALE_OUT**: The window scale factor for outgoing traffic.\n",
    "* **SRC_TOS**: The Type of Service (ToS) value for the source IP address.\n",
    "* **DST_TOS**: The Type of Service (ToS) value for the destination IP address.\n",
    "* **TOTAL_FLOWS_EXP**: The total number of expected flows.\n",
    "* **MIN_IP_PKT_LEN**: The minimum length (in bytes) of IP packets in the flow.\n",
    "* **MAX_IP_PKT_LEN**: The maximum length (in bytes) of IP packets in the flow.\n",
    "* **TOTAL_PKTS_EXP**: The total number of expected packets in the flow.\n",
    "* **TOTAL_BYTES_EXP**: The total number of expected bytes in the flow.\n",
    "* **IN_BYTES**: The number of bytes received in the flow.\n",
    "* **IN_PKTS**: The number of packets received in the flow.\n",
    "* **OUT_BYTES**: The number of bytes sent in the flow.\n",
    "* **OUT_PKTS**: The number of packets sent in the flow.\n",
    "* **ANALYSIS_TIMESTAMP**: The time at which the flow was analyzed, measured in seconds since the epoch (January 1, 1970).\n",
    "* **ANOMALY**: A binary flag indicating whether the flow contains an anomaly (1 = true, 0 = false).\n",
    "* **ALERT**: (<u>only available in training set</u>) The kind of attack that has been detected on the current flow. This are the possible values:\n",
    "  - **None**: No attack has been detected\n",
    "  - **Port scanning**: The flow is a port scanning attack\n",
    "  - **Denial of Service**: The flow is a DoS attack\n",
    "  - **Malware**: The flow is a malware attack\n",
    "* **ID**: A unique identifier for the flow.\n",
    "\n",
    "## Tested models\n",
    "\n",
    "* K-Nearest Neighbors (KNN)\n",
    "* Support Vector Machine Classifier (SVC) with RBF (Radial Basis Function) kernel\n",
    "* Pipeline with Principal Component Analysis (PCA) and Support Vector Machine Classifier (SVC)\n",
    "* Bagging Classifier (based on SVC with RBF kernel)\n",
    "* Random Forest Classifier\n",
    "* Extra Trees Classifier\n",
    "* Neural Network (MLPClassifier)"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 1. Datasets loading"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### 1.1. Importing the basic libraries"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Load data processing libraries\n",
    "import pandas as pd\n",
    "import numpy as np\n",
    "import matplotlib.pyplot as plt\n",
    "import seaborn as sns\n",
    "import math\n",
    "%matplotlib inline"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### 1.2. Importing machine learning libraries"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Load machine learning libraries\n",
    "from sklearn.metrics import classification_report, confusion_matrix\n",
    "from sklearn.ensemble import RandomForestClassifier, ExtraTreesClassifier, BaggingClassifier\n",
    "from sklearn.preprocessing import StandardScaler\n",
    "from sklearn.model_selection import StratifiedShuffleSplit, GridSearchCV, cross_val_score\n",
    "from sklearn.neighbors import KNeighborsClassifier\n",
    "from sklearn.svm import SVC\n",
    "from sklearn.pipeline import make_pipeline\n",
    "from sklearn.decomposition import PCA\n",
    "from sklearn.neural_network import MLPClassifier"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### 1.3. Development mode flag"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# If true, only the 3% of the data will be used for training and testing of the various models\n",
    "_DEVMODE = True"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### 1.4. Loading the datasets"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Loading the data from the train and test files\n",
    "train_df = pd.read_csv('data/train_net.csv')\n",
    "test_df = pd.read_csv('data/test_net.csv')"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### 1.5. Loaded datasets information"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Print total size\n",
    "print(\"Test set size: \", test_df.shape)\n",
    "print(\"Train set size: \", train_df.shape)\n",
    "\n",
    "# Value counts\n",
    "train_df['ALERT'].value_counts()"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### 1.6. Dataset development mode reduction"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "if _DEVMODE:\n",
    "    train_df = train_df.sample(frac=0.03, random_state=1)\n",
    "    test_df = test_df.sample(frac=0.03, random_state=1)\n",
    "\n",
    "    # Print total size\n",
    "    print(\"Test set size: \", test_df.shape)\n",
    "    print(\"Train set size: \", train_df.shape)\n"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 2. Data preprocessing"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### 2.1. Print datasets information"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "train_df.info()"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### 2.2. Print datasets shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Show information about the data\n",
    "def printInfo(df):\n",
    "    print('Dataframe shape: ', df.shape)\n",
    "    print('Dataframe columns: ', df.columns)\n",
    "\n",
    "print('==== Train data ====')\n",
    "printInfo(train_df)\n",
    "print()\n",
    "print('==== Test data ====')\n",
    "printInfo(test_df)"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### 2.3. Show training dataset structure"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "train_df.head()"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### 2.4 Check for missing values"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Check for missing values\n",
    "print('==== Train data ====')\n",
    "print(train_df.isnull().sum())\n",
    "print()\n",
    "print('==== Test data ====')\n",
    "print(test_df.isnull().sum())\n",
    "print()"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### 2.5 Fill missing **ANOMALY** values"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Fill the missing ANOMALY values with 0 (no anomaly)\n",
    "train_df['ANOMALY'].fillna(0, inplace=True)\n",
    "test_df['ANOMALY'].fillna(0, inplace=True)"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 3. Data analysis"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### 3.1. Data types"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "train_df.dtypes"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### 3.2. Observing the distribution of the target variable"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Show the distribution of the target variable\n",
    "sns.countplot(x='ALERT', data=train_df)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Count the number of unique protocol_maps\n",
    "train_df['PROTOCOL_MAP'].value_counts()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "fig, axs = plt.subplots(1, 3, figsize=(20, 5))\n",
    "\n",
    "# seaborn countplots\n",
    "sns.countplot(x='ANOMALY', data=train_df, ax=axs[0]).set(title='ANOMALY')\n",
    "              \n",
    "\n",
    "# Seaborn countplot for the 'PROTOCOL_MAP' column, with enough space for the labels\n",
    "sns.countplot(x='PROTOCOL_MAP', data=train_df, ax=axs[1]).set(title='PROTOCOL_MAP')\n",
    "\n",
    "# Boxplot for L4_SRC_PORT to undestand the distribution of the data\n",
    "sns.boxplot(\n",
    "    x='L4_SRC_PORT', data=train_df, ax=axs[2],\n",
    "    notch=True, showcaps=True,\n",
    "    flierprops={\"marker\": \"x\"}, # Change the outlier marker\n",
    "    showmeans=True, # Show the mean\n",
    "    boxprops={\"facecolor\": (.4, .6, .8, .5)},\n",
    "  ).set(title='L4_SRC_PORT')"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### 3.3. Protocol distribution in relation to the kind of attack"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Show protocol_map distribution for kind of ALERT\n",
    "sns.countplot(x='PROTOCOL_MAP', hue='ALERT', data=train_df)"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### 3.4. Unique hosts in dataset"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Find unique hosts (IP addresses) in the train and test data\n",
    "train_src_hosts = train_df['IPV4_SRC_ADDR'].unique()\n",
    "train_dst_hosts = train_df['IPV4_DST_ADDR'].unique()\n",
    "train_hosts = np.union1d(train_src_hosts, train_dst_hosts)\n",
    "\n",
    "# For each host, count the number of flows\n",
    "print('Number of unique hosts in the train data: ', len(train_hosts))\n",
    "\n",
    "# Find unique hosts (IP addresses) in the train and test data\n",
    "test_src_hosts = test_df['IPV4_SRC_ADDR'].unique()\n",
    "test_dst_hosts = test_df['IPV4_DST_ADDR'].unique()\n",
    "test_hosts = np.union1d(test_src_hosts, test_dst_hosts)\n",
    "\n",
    "# Floor ratio of hosts in test data that are not in train data\n",
    "ratio = math.floor((1.0-len(test_hosts)/len(train_hosts)) * 100)\n",
    "\n",
    "# For each host, count the number of flows\n",
    "print(\"Number of unique hosts in the test data: {} (~{}% smaller)\".format(len(test_hosts), ratio))\n"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### 3.5. Distribution analysis using pairplot"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# select the columns to be used for training\n",
    "train_df_columns = train_df[['L4_SRC_PORT', 'L4_DST_PORT', 'PROTOCOL', 'ANOMALY', 'ALERT']]\n",
    "\n",
    "# Distribution analysis using pairplot\n",
    "sns.pairplot(train_df_columns, hue='ALERT')"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### 3.6. Remove useless columns and create dummies"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Revoked columns\n",
    "revoked_columns = [\n",
    "  'FLOW_ID', # Completely random\n",
    "  'ID', # Completely random\n",
    "  'ANALYSIS_TIMESTAMP', # Completely random\n",
    "  'IPV4_SRC_ADDR', # Not useful for the model\n",
    "  'IPV4_DST_ADDR', # Not useful for the model\n",
    "  'PROTOCOL_MAP', # There is a numerical column for the protocol\n",
    "  'MIN_IP_PKT_LEN', # Always 0 since it is a minimum value\n",
    "  'MAX_IP_PKT_LEN', # Always 0 (maybe it means that the packet have infinite length?)\n",
    "  'TOTAL_PKTS_EXP', # Always 0\n",
    "  'TOTAL_BYTES_EXP', # Always 0\n",
    "]\n",
    "\n",
    "# Create dummy columns for the ALERT column\n",
    "alert_dummies = pd.get_dummies(train_df['ALERT'], prefix='ALERT', drop_first=True)\n",
    "\n",
    "# Copy + drop the revoked columns\n",
    "train_df = train_df.copy().drop(revoked_columns, axis=1)"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### 3.7. Correlation heatmap"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Correlation heatmap using pandas\n",
    "corr = pd.concat([train_df.drop('ALERT', axis=1), alert_dummies], axis=1).corr(\n",
    "  numeric_only=False, # Only consider numeric columns\n",
    ")\n",
    "\n",
    "# Correlation heatmap using seaborn + make annotations fit the heatmap\n",
    "plt.figure(figsize=(20, 20))\n",
    "sns.heatmap(corr, annot=True, fmt=\".1f\", cmap=\"YlGnBu\")"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 4. Dataset preparation\n"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### 4.1. Splitting the training set"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def split_maintain_distribution(X, y):\n",
    "  sss=StratifiedShuffleSplit(n_splits=1, test_size=0.2, random_state=9)\n",
    "  indexes = sss.split(X, y)\n",
    "  train_indices, test_indices = next(indexes)\n",
    "  return X.iloc[train_indices], X.iloc[test_indices], y.iloc[train_indices], y.iloc[test_indices]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "X_train, X_val, y_train, y_val = split_maintain_distribution(train_df.drop('ALERT', axis=1), train_df['ALERT'])"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### 4.1.1 Check if the datasets are balanced"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Print distribution of the target variable in the train and validation sets\n",
    "print('Train set distribution:')\n",
    "print(y_train.value_counts(normalize=True))\n",
    "print()\n",
    "print('Validation set distribution:')\n",
    "print(y_val.value_counts(normalize=True))"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### 4.2. Data scaling"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Fix scaler on train set\n",
    "scaler = StandardScaler()\n",
    "fitter = scaler.fit(X_train)\n",
    "\n",
    "# Scale train and validation sets\n",
    "x_train_scaled = fitter.transform(X_train)\n",
    "x_validation_scaled = fitter.transform(X_val)\n",
    "\n",
    "# Convert to pandas dataframe\n",
    "df_feat_train = pd.DataFrame(x_train_scaled, columns=X_train.columns)\n",
    "df_feat_validation = pd.DataFrame(x_validation_scaled, columns=X_val.columns)"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 5. Feature selection"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### 5.1. Create model and fit it"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Random Forest Classifier\n",
    "rfc = RandomForestClassifier(n_estimators=100) # 100 trees = default value\n",
    "\n",
    "# Fit the model\n",
    "rfc.fit(x_train_scaled, y_train)"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### 5.2. Get feature importances"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Print features importance\n",
    "feature_importances = pd.DataFrame(\n",
    "    rfc.feature_importances_,\n",
    "    index=X_train.columns,\n",
    "    columns=['importance']\n",
    ").sort_values('importance', ascending=False)\n",
    "print(feature_importances)"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### 5.3. Plot feature importances"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Plot feature importance\n",
    "plt.figure(figsize=(20, 10))\n",
    "plt.xticks(rotation=-90)\n",
    "sns.barplot(x=feature_importances.index, y=feature_importances['importance'])"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### 5.4. Select most important features"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "MIN_IMPORTANCE_THRESHOLD = 0.02"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Select all columns with importance > 0.02\n",
    "COLUMNS = feature_importances[feature_importances['importance'] > MIN_IMPORTANCE_THRESHOLD].index\n",
    "COLUMNS"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### 5.5. Reprepare the dataset with the selected features"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### 5.5.1. Split again the training set into training and validation sets (with new features)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "X_train, X_val, y_train, y_val = split_maintain_distribution(\n",
    "  train_df[COLUMNS],\n",
    "  train_df['ALERT']\n",
    ")"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### 5.5.2. Scale again the train and validation sets (with new features)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Fix scaler on train set\n",
    "scaler = StandardScaler()\n",
    "fitter = scaler.fit(X_train)\n",
    "\n",
    "# Scale train and validation sets\n",
    "x_train_scaled = fitter.transform(X_train)\n",
    "x_validation_scaled = fitter.transform(X_val)\n",
    "\n",
    "# Convert to pandas dataframe\n",
    "df_feat_train = pd.DataFrame(x_train_scaled, columns=X_train.columns)\n",
    "df_feat_validation = pd.DataFrame(x_validation_scaled, columns=X_val.columns)"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### 5.5.3. Scale also the test set (with new features)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# No target variable, so no need to split the fit and transform\n",
    "x_test_scaled = StandardScaler().fit_transform(test_df[COLUMNS])\n",
    "# Convert to pandas dataframe\n",
    "df_feat_test = pd.DataFrame(x_test_scaled, columns=test_df[COLUMNS].columns)"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 6. Model Training\n",
    "\n",
    "* K-Nearest Neighbors (KNN)\n",
    "* Support Vector Machine (SVM) with RBF kernel (Radial Basis Function)\n",
    "  * SVC\n",
    "  * SVC with PCA (Principal Component Analysis) pipeline\n",
    "* Bagging Classifier (SVC with RBF kernel)\n",
    "* Random Forest Classifier\n",
    "* Extra Trees Classifier\n",
    "* Neural Network (MLPClassifier)"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### 6.1. KNN Classifier training"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### 6.1.1 Finding the best K hyperparameter for KNN"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Find best K using GridSearchCV\n",
    "MAX_DEGREE = 30\n",
    "\n",
    "k_range = list(range(1, MAX_DEGREE+1))\n",
    "param_grid = dict(n_neighbors=k_range)\n",
    "knn = KNeighborsClassifier()\n",
    "grid = GridSearchCV(knn, param_grid, cv=3, scoring='accuracy', n_jobs=-1)\n",
    "grid.fit(x_train_scaled, y_train)\n",
    "\n",
    "# Print information about the model\n",
    "print(f\"Best k: {grid.best_params_}\")\n",
    "print(f\"Best score: {grid.best_score_}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Plot results\n",
    "plt.figure(num=0, dpi=96, figsize=(10, 6))\n",
    "plt.plot(k_range, grid.cv_results_['mean_test_score'])\n",
    "plt.xlabel('Value of K for KNN')\n",
    "plt.ylabel('Cross-Validated Accuracy')\n",
    "plt.xticks(k_range)\n",
    "plt.show()"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### 6.1.2. Fit model with best K hyperparameter + make predictions"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Create a KNN classifier with 3 neighbors\n",
    "knn = KNeighborsClassifier(n_neighbors=3) # 3 = view note above\n",
    "# Fit the classifier to the data\n",
    "knn.fit(x_train_scaled, y_train)\n",
    "# Make predictions on validation set\n",
    "predictions = knn.predict(x_validation_scaled)"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### 6.1.3. Model evaluation based on validation set predictions"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Print the classification report\n",
    "print(classification_report(y_val, predictions))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Rename the columns and index for the confusion matrix\n",
    "cmat = confusion_matrix(y_val, predictions)\n",
    "cmat = pd.DataFrame(cmat, index=['Denial of Service', 'Malware', 'None', 'Port Scan'], columns=['Denial of Service', 'Malware', 'None', 'Port Scan'])\n",
    "\n",
    "# Use seaborn to visualize the confusion matrix\n",
    "sns.set(font_scale=1.4) # for label size\n",
    "sns.heatmap(cmat, annot=True, fmt='d', cmap='YlGnBu')"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### 6.1.4. KNN predictions on test set"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Prediction on the test set\n",
    "predictions = knn.predict(x_test_scaled)\n",
    "\n",
    "# Show the predictions on a histogram\n",
    "fig = sns.countplot(x=predictions)\n",
    "fig.set_title('Predictions distribution on the test set') # Set the title\n",
    "fig.set_xticklabels(fig.get_xticklabels(), rotation=45) # Rotate x-labels\n",
    "pd.Series(predictions).value_counts() # Print the predictions size per class"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### 6.2. Support Vector Machine Classifier (SVC) training"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### 6.2.1 Only SVC model training"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "##### 6.2.1.1. Grid search to find best hyperparameters for SVC"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Create grid search parameters\n",
    "param_grid = {\n",
    "  'C': [0.1, 1, 10, 100, 1000],\n",
    "  'gamma': [1, 0.1, 0.01, 0.001, 0.0001],\n",
    "}\n",
    "\n",
    "# Create grid search\n",
    "svc_grid = GridSearchCV(\n",
    "  SVC(kernel=\"rbf\"),\n",
    "  param_grid,\n",
    "  cv=2, # Only 2 folds because of the size of the dataset, otherwise it takes too long\n",
    "  n_jobs=-1, # Use all cores\n",
    ")\n",
    "\n",
    "# Fit grid search\n",
    "svc_grid.fit(x_train_scaled, y_train)\n",
    "\n",
    "# Print information about the model\n",
    "print(f\"Best params: {svc_grid.best_params_}\")\n",
    "print(f\"Best score: {svc_grid.best_score_}\")"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "##### 6.2.1.2. Create model with best parameters + fit model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Create SVM with best parameters\n",
    "svc = SVC(\n",
    "  kernel='rbf',\n",
    "  C=svc_grid.best_params_['C'],\n",
    "  gamma=svc_grid.best_params_['gamma'],\n",
    ")\n",
    "svc.fit(x_train_scaled, y_train)"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "##### 6.2.1.3. Make predictions"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Make predictions on validation set\n",
    "predictions = svc.predict(x_validation_scaled)"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "##### 6.2.1.4. Model evaluation"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Print the classification report\n",
    "print(classification_report(y_val, predictions))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Rename the columns and index for the confusion matrix\n",
    "cmat = confusion_matrix(y_val, predictions)\n",
    "cmat = pd.DataFrame(cmat, index=['Denial of Service', 'Malware', 'None', 'Port Scan'], columns=['Denial of Service', 'Malware', 'None', 'Port Scan'])\n",
    "\n",
    "# Use seaborn to visualize the confusion matrix\n",
    "sns.set(font_scale=1.4) # for label size\n",
    "sns.heatmap(cmat, annot=True, fmt='d', cmap='YlGnBu')"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "##### 6.2.1.5. SVC model predictions on test set"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Prediction on the test set\n",
    "predictions = svc.predict(x_test_scaled)\n",
    "\n",
    "# Show the predictions on a histogram\n",
    "fig = sns.countplot(x=predictions)\n",
    "fig.set_title('Predictions distribution on the test set') # Set the title\n",
    "fig.set_xticklabels(fig.get_xticklabels(), rotation=45) # Rotate x-labels\n",
    "pd.Series(predictions).value_counts() # Print the predictions size per class"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### 6.2.2. PCA + SVC model training"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "##### 6.2.2.1. Create pipeline"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Create the two parameters\n",
    "pca = PCA(whiten=True, random_state=42) # PCA (Principal Component Analysis)\n",
    "svc = SVC(kernel='rbf', class_weight='balanced') # SVC (Support Vector Classification)\n",
    "\n",
    "# Create pipeline\n",
    "model = make_pipeline(pca, svc)"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "##### 6.2.2.2. Grid search to find the best parameters for PCA and SVC"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Generate a valid n_components range (from 5 to maximum number of features)\n",
    "n_features = x_train_scaled.shape[1]\n",
    "n_components = np.arange(5, n_features, 3)\n",
    "\n",
    "param_grid = {\n",
    "  'pca__n_components': n_components,\n",
    "  'svc__C': [50, 100, 500, 1000, 5000, 10000],\n",
    "  'svc__gamma': [0.001, 0.01, 0.1, 1, 10]\n",
    "}\n",
    "\n",
    "# Grid search \n",
    "pipeline_grid = GridSearchCV(\n",
    "    model,\n",
    "    param_grid,\n",
    "    cv=2, # Only 2 folds because of the size of the dataset, otherwise it takes too long\n",
    "    n_jobs=-1 # Use all cores\n",
    ")\n",
    "pipeline_grid.fit(x_train_scaled, y_train)\n",
    "\n",
    "# Print information about the model\n",
    "print(f\"Best params: {pipeline_grid.best_params_}\")\n",
    "print(f\"Best score: {pipeline_grid.best_score_}\")"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "##### 6.2.2.3. Create pipeline with best parameters + fit model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Now, create the desired pipeline\n",
    "pca = PCA(\n",
    "  n_components=pipeline_grid.best_params_['pca__n_components'],\n",
    "  whiten=True,\n",
    "  random_state=42\n",
    ")\n",
    "svc = SVC(kernel='rbf',\n",
    "  class_weight='balanced',\n",
    "  # Use the best parameters found by the grid search\n",
    "  C=pipeline_grid.best_params_['svc__C'],\n",
    "  gamma=pipeline_grid.best_params_['svc__gamma']\n",
    ")\n",
    "model = make_pipeline(pca, svc)\n",
    "model.fit(x_train_scaled, y_train)"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "##### 6.2.2.4. Make predictions"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Make predictions on validation set\n",
    "predictions = model.predict(x_validation_scaled)"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "##### 6.2.2.5. Model evaluation"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Print the classification report\n",
    "print(classification_report(y_val, predictions))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Rename the columns and index for the confusion matrix\n",
    "cmat = confusion_matrix(y_val, predictions)\n",
    "cmat = pd.DataFrame(cmat, index=['Denial of Service', 'Malware', 'None', 'Port Scan'], columns=['Denial of Service', 'Malware', 'None', 'Port Scan'])\n",
    "\n",
    "# Use seaborn to visualize the confusion matrix\n",
    "sns.set(font_scale=1.4) # for label size\n",
    "sns.heatmap(cmat, annot=True, fmt='d', cmap='YlGnBu')"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "##### 6.2.2.6. SVC+PCA pipeline model predictions on test set"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Prediction on the test set\n",
    "predictions = model.predict(x_test_scaled)\n",
    "\n",
    "# Show the predictions on a histogram\n",
    "fig = sns.countplot(x=predictions)\n",
    "fig.set_title('Predictions distribution on the test set') # Set the title\n",
    "fig.set_xticklabels(fig.get_xticklabels(), rotation=45) # Rotate x-labels\n",
    "pd.Series(predictions).value_counts() # Print the predictions size per class"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### 6.3. Bagging Classifier (SVC based) training"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### 6.3.1. Create model using best SVC parameters + fit model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "svc = SVC(kernel='rbf',\n",
    "  class_weight='balanced',\n",
    "  C=svc_grid.best_params_['C'],\n",
    "  gamma=svc_grid.best_params_['gamma']\n",
    ")\n",
    "\n",
    "clf = BaggingClassifier(\n",
    "  svc,\n",
    "  n_estimators=30,\n",
    "  n_jobs=-1, # Use all cores\n",
    "  random_state=42\n",
    ")\n",
    "clf.fit(x_train_scaled, y_train)"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### 6.3.2. Make predictions"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "predictions = clf.predict(x_validation_scaled)"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### 6.3.3. Model evaluation"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Print the classification report\n",
    "print(classification_report(y_val, predictions))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Rename the columns and index for the confusion matrix\n",
    "cmat = confusion_matrix(y_val, predictions)\n",
    "cmat = pd.DataFrame(cmat, index=['Denial of Service', 'Malware', 'None', 'Port Scan'], columns=['Denial of Service', 'Malware', 'None', 'Port Scan'])\n",
    "\n",
    "# Use seaborn to visualize the confusion matrix\n",
    "sns.set(font_scale=1.4) # for label size\n",
    "sns.heatmap(cmat, annot=True, fmt='d', cmap='YlGnBu')"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### 6.5.5. Bagging Classifier predictions on test set"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Prediction on the test set\n",
    "predictions = clf.predict(x_test_scaled)\n",
    "\n",
    "# Show the predictions on a histogram\n",
    "fig = sns.countplot(x=predictions)\n",
    "fig.set_title('Predictions distribution on the test set') # Set the title\n",
    "fig.set_xticklabels(fig.get_xticklabels(), rotation=45) # Rotate x-labels\n",
    "pd.Series(predictions).value_counts() # Print the predictions size per class"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### 6.4. Random Forest Classifier training"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### 6.4.1. Grid search to find best hyperparameters for Random Forest"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Create random forest classifier\n",
    "rfc = RandomForestClassifier()\n",
    "\n",
    "# Create a dictionary of all values we want to test for n_estimators\n",
    "parameters = {'n_estimators': [1, 2, 4, 10, 15, 20, 30, 40, 50, 100, 200, 500, 1000]}\n",
    "\n",
    "# Used to find the best n_estimators value to use to train the model\n",
    "rfc_grid = GridSearchCV(\n",
    "  rfc,\n",
    "  parameters,\n",
    "  scoring='accuracy',\n",
    "  cv=2, # Only 2 folds because of the size of the dataset, otherwise it takes too long\n",
    "  n_jobs=-1 # Use all cores\n",
    ")\n",
    "\n",
    "# Fit model to data\n",
    "rfc_grid.fit(x_train_scaled, y_train)\n",
    "\n",
    "# Extract best params\n",
    "print(f\"Best params: {rfc_grid.best_params_}\")\n",
    "print(f\"Best score: {rfc_grid.best_score_}\")"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### 6.4.2. Create model with best parameters + fit model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "rfc = RandomForestClassifier(n_estimators=rfc_grid.best_params_['n_estimators'])\n",
    "rfc.fit(x_train_scaled, y_train)"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### 6.4.3. Make predictions"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Make predictions on validation set\n",
    "predictions = rfc.predict(x_validation_scaled)"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### 6.4.4. Model evaluation"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Print the classification report\n",
    "print(classification_report(y_val, predictions))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Rename the columns and index for the confusion matrix\n",
    "cmat = confusion_matrix(y_val, predictions)\n",
    "cmat = pd.DataFrame(cmat, index=['Denial of Service', 'Malware', 'None', 'Port Scan'], columns=['Denial of Service', 'Malware', 'None', 'Port Scan'])\n",
    "\n",
    "# Use seaborn to visualize the confusion matrix\n",
    "sns.set(font_scale=1.4) # for label size\n",
    "sns.heatmap(cmat, annot=True, fmt='d', cmap='YlGnBu')"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### 6.5.5. Random Forest model predictions on test set"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Prediction on the test set\n",
    "predictions = rfc.predict(x_test_scaled)\n",
    "\n",
    "# Show the predictions on a histogram\n",
    "fig = sns.countplot(x=predictions)\n",
    "fig.set_title('Predictions distribution on the test set') # Set the title\n",
    "fig.set_xticklabels(fig.get_xticklabels(), rotation=45) # Rotate x-labels\n",
    "pd.Series(predictions).value_counts() # Print the predictions size per class"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### 6.5. Extra Trees Classifier training"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### 6.5.1. Grid search to find best hyperparameters for Extra Trees"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Create random forest classifier\n",
    "etc = ExtraTreesClassifier()\n",
    "\n",
    "# Create a dictionary of all values we want to test for n_estimators\n",
    "parameters = {'n_estimators': [1, 2, 4, 10, 15, 20, 30, 40, 50, 100, 200, 500]}\n",
    "\n",
    "# Used to find the best n_estimators value to use to train the model\n",
    "etc_grid = GridSearchCV(\n",
    "  etc,\n",
    "  parameters,\n",
    "  scoring='accuracy',\n",
    "  cv=2, # Only 2 folds because of the size of the dataset, otherwise it takes too long\n",
    "  n_jobs=-1 # Use all cores\n",
    ")\n",
    "\n",
    "# Fit model to data\n",
    "etc_grid.fit(x_train_scaled, y_train)\n",
    "\n",
    "# Extract best params\n",
    "print(f\"Best params: {etc_grid.best_params_}\")\n",
    "print(f\"Best score: {etc_grid.best_score_}\")"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### 6.5.2. Create model with best parameters + fit model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "etc = ExtraTreesClassifier(n_estimators=etc_grid.best_params_['n_estimators'])\n",
    "etc.fit(x_train_scaled, y_train)"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### 6.5.3. Make predictions"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Make predictions on validation set\n",
    "predictions = etc.predict(x_validation_scaled)"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### 6.5.4. Model evaluation"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Print the classification report\n",
    "print(classification_report(y_val, predictions))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Rename the columns and index for the confusion matrix\n",
    "cmat = confusion_matrix(y_val, predictions)\n",
    "cmat = pd.DataFrame(cmat, index=['Denial of Service', 'Malware', 'None', 'Port Scan'], columns=['Denial of Service', 'Malware', 'None', 'Port Scan'])\n",
    "\n",
    "# Use seaborn to visualize the confusion matrix\n",
    "sns.set(font_scale=1.4) # for label size\n",
    "sns.heatmap(cmat, annot=True, fmt='d', cmap='YlGnBu')"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### 6.5.5. Extra Trees model predictions on test set"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Prediction on the test set\n",
    "predictions = etc.predict(x_test_scaled)\n",
    "\n",
    "# Show the predictions on a histogram\n",
    "fig = sns.countplot(x=predictions)\n",
    "fig.set_title('Predictions distribution on the test set') # Set the title\n",
    "fig.set_xticklabels(fig.get_xticklabels(), rotation=45) # Rotate x-labels\n",
    "pd.Series(predictions).value_counts() # Print the predictions size per class"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### 6.6. Neural Network classifier training"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### 6.6.1. Grid search to find best hyperparameters for Neural Network"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Create MLPClasifier\n",
    "mlp = MLPClassifier(\n",
    "  max_iter=1000,\n",
    "  random_state=42\n",
    ")\n",
    "\n",
    "# Grid search for MLPClassifier\n",
    "parameters = {\n",
    "  'hidden_layer_sizes': [(50,), (100,), (50, 50)],\n",
    "  'activation': ['relu', 'tanh'],\n",
    "  'alpha': [0.0001, 0.001],\n",
    "  'solver': ['adam', 'lbfgs'],\n",
    "  'learning_rate': ['constant', 'invscaling'],\n",
    "}\n",
    "\n",
    "mlp_grid = GridSearchCV(\n",
    "  mlp,\n",
    "  parameters,\n",
    "  cv=2, # Only 2 folds because of the size of the dataset, otherwise it takes too long\n",
    "  n_jobs=-1, # Use all cores\n",
    ")\n",
    "\n",
    "mlp_grid.fit(x_train_scaled, y_train)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Extract best params\n",
    "print(f\"Best params: {mlp_grid.best_params_}\")\n",
    "print(f\"Best score: {mlp_grid.best_score_}\")"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### 6.6.2. Create model with best parameters + fit model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Create MLPClassifier with best parameters\n",
    "mlp = MLPClassifier(\n",
    "  hidden_layer_sizes=mlp_grid.best_params_['hidden_layer_sizes'],\n",
    "  activation=mlp_grid.best_params_['activation'],\n",
    "  alpha=mlp_grid.best_params_['alpha'],\n",
    "  solver=mlp_grid.best_params_['solver'],\n",
    "  learning_rate=mlp_grid.best_params_['learning_rate'],\n",
    "  max_iter=1000,\n",
    "  random_state=42\n",
    ")\n",
    "mlp.fit(x_train_scaled, y_train)"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### 6.6.3. Make predictions"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Make predictions on validation set\n",
    "predictions = mlp.predict(x_validation_scaled)"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### 6.6.4. Model evaluation"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Print the classification report\n",
    "print(classification_report(y_val, predictions))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Rename the columns and index for the confusion matrix\n",
    "cmat = confusion_matrix(y_val, predictions)\n",
    "cmat = pd.DataFrame(cmat, index=['Denial of Service', 'Malware', 'None', 'Port Scan'], columns=['Denial of Service', 'Malware', 'None', 'Port Scan'])\n",
    "\n",
    "# Use seaborn to visualize the confusion matrix\n",
    "sns.set(font_scale=1.4) # for label size\n",
    "sns.heatmap(cmat, annot=True, fmt='d', cmap='YlGnBu')"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### 6.6.5. MPL classifier model predictions on test set"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Prediction on the test set\n",
    "predictions = mlp.predict(x_test_scaled)\n",
    "\n",
    "# Show the predictions on a histogram\n",
    "fig = sns.countplot(x=predictions)\n",
    "fig.set_title('Predictions distribution on the test set') # Set the title\n",
    "fig.set_xticklabels(fig.get_xticklabels(), rotation=45) # Rotate x-labels\n",
    "pd.Series(predictions).value_counts() # Print the predictions size per class"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "machinelearning",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.6"
  },
  "orig_nbformat": 4
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
